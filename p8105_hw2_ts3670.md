P8105_hw2_ts3670
================
Tong Su
2024-10-02

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
library(dplyr)
```

\##Problem 1 - NYC Transit data

Read in the NYC Transit data and clean the data.

``` r
NYtrans_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
                      na = c(".", "NA", ""),
           col_types = cols(
             Route8 = col_character(),
             Route9 = col_character(),
             Route10 = col_character(),
             Route11 = col_character()
             )
           ) |>
  janitor::clean_names() |>
  select(line:entry, vending, ada) |>
  mutate(entry = ifelse(entry=="YES",TRUE,FALSE))
```

``` r
skimr::skim(NYtrans_df)
```

|                                                  |            |
|:-------------------------------------------------|:-----------|
| Name                                             | NYtrans_df |
| Number of rows                                   | 1868       |
| Number of columns                                | 19         |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |            |
| Column type frequency:                           |            |
| character                                        | 15         |
| logical                                          | 2          |
| numeric                                          | 2          |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |            |
| Group variables                                  | None       |

Data summary

**Variable type: character**

| skim_variable | n_missing | complete_rate | min | max | empty | n_unique | whitespace |
|:--------------|----------:|--------------:|----:|----:|------:|---------:|-----------:|
| line          |         0 |          1.00 |   5 |  17 |     0 |       36 |          0 |
| station_name  |         0 |          1.00 |   4 |  39 |     0 |      356 |          0 |
| route1        |         0 |          1.00 |   1 |   2 |     0 |       24 |          0 |
| route2        |       848 |          0.55 |   1 |   2 |     0 |       20 |          0 |
| route3        |      1374 |          0.26 |   1 |   2 |     0 |       18 |          0 |
| route4        |      1547 |          0.17 |   1 |   1 |     0 |       13 |          0 |
| route5        |      1630 |          0.13 |   1 |   1 |     0 |       12 |          0 |
| route6        |      1741 |          0.07 |   1 |   1 |     0 |        7 |          0 |
| route7        |      1788 |          0.04 |   1 |   2 |     0 |        7 |          0 |
| route8        |      1820 |          0.03 |   1 |   1 |     0 |        3 |          0 |
| route9        |      1840 |          0.01 |   1 |   1 |     0 |        2 |          0 |
| route10       |      1845 |          0.01 |   1 |   1 |     0 |        1 |          0 |
| route11       |      1845 |          0.01 |   1 |   1 |     0 |        1 |          0 |
| entrance_type |         0 |          1.00 |   4 |   9 |     0 |        7 |          0 |
| vending       |         0 |          1.00 |   2 |   3 |     0 |        2 |          0 |

**Variable type: logical**

| skim_variable | n_missing | complete_rate | mean | count               |
|:--------------|----------:|--------------:|-----:|:--------------------|
| entry         |         0 |             1 | 0.94 | TRU: 1753, FAL: 115 |
| ada           |         0 |             1 | 0.25 | FAL: 1400, TRU: 468 |

**Variable type: numeric**

| skim_variable     | n_missing | complete_rate |   mean |   sd |     p0 |    p25 |    p50 |    p75 |   p100 | hist  |
|:------------------|----------:|--------------:|-------:|-----:|-------:|-------:|-------:|-------:|-------:|:------|
| station_latitude  |         0 |             1 |  40.73 | 0.07 |  40.58 |  40.69 |  40.73 |  40.77 |  40.90 | ▂▅▇▃▂ |
| station_longitude |         0 |             1 | -73.94 | 0.06 | -74.03 | -73.99 | -73.96 | -73.91 | -73.76 | ▇▆▃▂▁ |

- The cleaned data of NYC transit contains 19 variables: line,
  station_name, station_latitude, station_longitude, route 1:11, entry,
  vending, entrance_type, and ada.
- The cleaning process includes that addressing the data type of route
  8:11, converting column names to lower snake case and converting the
  entry variable from charater variable to logical variable.
- The dimension of cleaned data is 1868 x 19

\#Questions: How many distinct stations are there?

``` r
distinct_stations = NYtrans_df |>
  distinct(station_name, line) |>
  nrow()
```

There are 465 stations.

How many stations are ADA compliant?

``` r
ada_compliant_stations = NYtrans_df |>
  filter(ada == TRUE) |>
  distinct(station_name, line) |>
  nrow()
```

There are 84 ADA compliant stations.

What proportion of station entrances / exits without vending allow
entrance?

``` r
proportion_without_vending = NYtrans_df |> 
  filter(vending == "NO") |> 
  pull(entry) |> 
  mean()
```

0.3770492 of station entrances/exits without vending all entrance.

How many distinct stations serve the A train?

``` r
Atrain_df = NYtrans_df |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A") |> 
  select(station_name, line) |> 
  distinct()
```

60 distinct stations serve A train.

Of the stations that serve the A train, how many are ADA compliant?

``` r
Atrain_ada_df = NYtrans_df |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A", ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

17 stations that serve A train are ADA compliant.

\##Problem 2 - Mr.Trash Wheel

``` r
mrTW_df = 
  read_excel("./data/202409 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel",skip = 1)|>
  filter(!is.na(Dumpster)) |>
  janitor::clean_names()|> 
  select (-x15, -x16) |>
  mutate(sports_balls = as.integer(round (sports_balls,0)),
         year = as.double(year),
         trash_wheel = "Mr"
  )
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
profTW_df =
  read_excel("./data/202409 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", skip = 1) |>
  filter(!is.na(Dumpster)) |>
  janitor::clean_names()|> 
  mutate(trash_wheel = "Professor")
```

``` r
gwyTW_df =
  read_excel("./data/202409 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1) |>
  filter(!is.na(Dumpster)) |>
  janitor::clean_names()|> 
  mutate(trash_wheel = "Gwynnda")
```

``` r
combinedTW_df = bind_rows(mrTW_df,
  profTW_df,
  gwyTW_df
)
```

``` r
total_weight_prof = combinedTW_df |>
  filter(trash_wheel == "Professor") |>
  summarise(total_weight_prof = sum(weight_tons, na.rm = TRUE))
```

``` r
cig_butts_gwynnda_june_2022 <- combinedTW_df |>
  filter(trash_wheel == "Gwynnda", format(date, "%Y-%m") == "2022-06") |>
  summarise(cig_butts_gwynnda_june_2022 = sum(cigarette_butts, na.rm = TRUE))
```

In this combined data of “Mr Trash Wheel”, “Professor Trash Wheel”, and
“Gwynnda Trash Wheel”, we have 1033 observations.It has key variables
like weight,volume, plastic bottles, cigarette butts, polystyrene, glass
bottles, plastic bags, wrappers, sports balls and home powered. The
total weight of trash collected by Professor Trash Wheel is 246.74.The
total number of cigarette butts collected by Gwynnda in June of 2022 is
1.812^{4}.

\##Problem 3 - Great British Bake Off

``` r
bakers_df = read_csv('./data/gbb_datasets/bakers.csv') |>
  janitor::clean_names() |>
  separate(baker_name, into = c("baker", "last_name")) 
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

    ## Warning: Expected 2 pieces. Additional pieces discarded in 10 rows [8, 20, 60, 76, 80,
    ## 90, 96, 102, 108, 110].

``` r
bakes_df = read_csv('./data/gbb_datasets/bakes.csv') |>
  janitor::clean_names() |>
  mutate(baker = if_else(baker =='"Jo"',"Jo",baker))
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results_df = read_csv('./data/gbb_datasets/results.csv', skip = 2) |>
  janitor::clean_names() |>
  mutate(baker = if_else(baker =="Joanne","Jo",baker))
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
check_df= bakers_df |>
  anti_join(bakes_df, by = c("baker","series"))|>
  distinct("baker","series")
check_df
```

    ## # A tibble: 1 × 2
    ##   `"baker"` `"series"`
    ##   <chr>     <chr>     
    ## 1 baker     series

``` r
check_df2= bakers_df |>
  anti_join(results_df, by = c("baker","series"))|>
  distinct("baker","series")
check_df2
```

    ## # A tibble: 1 × 2
    ##   `"baker"` `"series"`
    ##   <chr>     <chr>     
    ## 1 baker     series

In order to merge these 3 datasets to create a single, final dataset, I
checked the completeness and correctness across datasets by anti_join
and discorvered that there exists inconsistensy in the name of bakers in
bakers_df and the other two. So I decide to remove the last name and
change the colume name of “name” in bakers_df, keep their first name as
“baker”. Also, the baker Joanne’s name were displayed differently across
these three datasets so I changed them to Jo by removing the extra “” in
bakes_df and “Joanne” in results_df to “Jo”.

``` r
bakers_bakes_results_df = results_df |>
  left_join(bakers_df, by = c("baker", "series")) |>
  left_join(bakes_df, by = c("baker", "series", "episode")) 

bakers_bakes_results_df = bakers_bakes_results_df |>
  arrange(series, episode)
```

``` r
file_path = file.path('./data/gbb_datasets/', "bakers_bakes_results.csv")

write_csv(bakers_bakes_results_df, file_path)
```

The full dataset merging by bakers.csv, bakes.csv, and results.csv has
the dimension of 1136 obs x 11 variable, each observation including
bake, baker, and result is represented as a row and arranged by seires
and episodes.

``` r
star_baker_df = bakers_bakes_results_df |>
  filter(series >= 5 ) |>
  select(series, episode, baker, result)|>
  filter(result == c("WINNER","STAR BAKER")) |>
  arrange(series, episode)
star_baker_df
```

    ## # A tibble: 30 × 4
    ##    series episode baker   result    
    ##     <dbl>   <dbl> <chr>   <chr>     
    ##  1      5       1 Nancy   STAR BAKER
    ##  2      5       3 Luis    STAR BAKER
    ##  3      5       8 Richard STAR BAKER
    ##  4      6       1 Marie   STAR BAKER
    ##  5      6       3 Ian     STAR BAKER
    ##  6      6       5 Nadiya  STAR BAKER
    ##  7      6       7 Tamal   STAR BAKER
    ##  8      6       9 Nadiya  STAR BAKER
    ##  9      6      10 Nadiya  WINNER    
    ## 10      7       1 Jane    STAR BAKER
    ## # ℹ 20 more rows

``` r
viewers_df = read_csv('./data/gbb_datasets/viewers.csv',
                      na = c(".", "NA", ""))|>
  janitor::clean_names()
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
(head(viewers_df, 10))
```

    ## # A tibble: 10 × 11
    ##    episode series_1 series_2 series_3 series_4 series_5 series_6 series_7
    ##      <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>
    ##  1       1     2.24     3.1      3.85     6.6      8.51     11.6     13.6
    ##  2       2     3        3.53     4.6      6.65     8.79     11.6     13.4
    ##  3       3     3        3.82     4.53     7.17     9.28     12.0     13.0
    ##  4       4     2.6      3.6      4.71     6.82    10.2      12.4     13.3
    ##  5       5     3.03     3.83     4.61     6.95     9.95     12.4     13.1
    ##  6       6     2.75     4.25     4.82     7.32    10.1      12       13.1
    ##  7       7    NA        4.42     5.1      7.76    10.3      12.4     13.4
    ##  8       8    NA        5.06     5.35     7.41     9.02     11.1     13.3
    ##  9       9    NA       NA        5.7      7.41    10.7      12.6     13.4
    ## 10      10    NA       NA        6.74     9.45    13.5      15.0     15.9
    ## # ℹ 3 more variables: series_8 <dbl>, series_9 <dbl>, series_10 <dbl>

``` r
avg_viewer_s1 = mean(viewers_df |> pull(series_1), na.rm = TRUE)
avg_viewer_s1 
```

    ## [1] 2.77

The average viewership in Season 1 is 2.77.

``` r
avg_viewer_s5 = mean(viewers_df |> pull(series_5))
avg_viewer_s5
```

    ## [1] 10.0393

The average viewership in Season 5 is 10.0393.
